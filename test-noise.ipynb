{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2da17bec-1b2e-45a4-a019-00dfdd043a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import save_image\n",
    "import torchvision.utils as vutils\n",
    "import os\n",
    "import datetime\n",
    "import time\n",
    "import lpips\n",
    "from pytorch_msssim import ssim  # 添加SSIM导入\n",
    "#start_time = datetime.datetime.now()\n",
    "#print(start_time)\n",
    "\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e56a47-4161-49b9-98be-6650c200df74",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:2\")\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94c83360-68af-446b-8a4b-20865069a67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,)),\n",
    "])\n",
    "test_set = datasets.MNIST(\n",
    "    root='./mnistdata',\n",
    "    train=False,\n",
    "    transform=transform,\n",
    "    download=True\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_set, batch_size=128, shuffle=False, num_workers=1, drop_last=True\n",
    ")\n",
    "real_labels = np.array([label for _, label in test_set])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5552c4ed-c757-45eb-b67c-fc9b15a78b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# state_dict\n",
    "model_path_hmvae = './saved_models_hmvae_mnist/model_epoch_496_loss_21.7908.pt'\n",
    "state_dict = torch.load(model_path_hmvae, map_location=device)\n",
    "model_path_MEMvae = './saved_models_MEMvae_mnist/model_epoch_498_loss_22.3760.pt'\n",
    "state_dict_MEMvae = torch.load(model_path_MEMvae, map_location=device)\n",
    "model_path_vae = './saved_models_vae_mnist/model_epoch_492_loss_23.7127.pt'\n",
    "state_dict_vae = torch.load(model_path_vae, map_location=device)\n",
    "model_path_cnn=\"./saved_models_cnn_mnist/model_epoch_27_acc_99.3590.pt\"\n",
    "state_dict_cnn=torch.load(model_path_cnn, map_location=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "febe90fe-4a12-4283-a7e3-828081d381f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from HMVAE import HMVAE\n",
    "n_levels = 3\n",
    "n_regions=2\n",
    "region_slot_config= [\n",
    "    ( [50, 50, 50], [64, 128, 256] ),  \n",
    "    ( [64, 64,64],   [32,64, 128] )      \n",
    "]\n",
    "latent_dim = 20\n",
    "hidden_dim =128\n",
    "image_channels = 1  # MNIST has 1 channel\n",
    "image_size = 28  # 28x28 images\n",
    "model_hmvae = HMVAE( n_levels, n_regions, region_slot_config,latent_dim,hidden_dim,image_channels,image_size).to(device)\n",
    "model_hmvae.load_state_dict(state_dict)\n",
    "model_hmvae.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fec32c5-3b53-4636-aae8-72a093ebcc99",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading 1-layers\n",
    "from MEMVAE import MEMVAE\n",
    "n_levels = 1\n",
    "num_slots_list = [50]  # Just example sizes\n",
    "slot_dim_list = [64]  # Example embedding sizes\n",
    "latent_dim = 20\n",
    "hidden_dim =128\n",
    "image_channels = 1  # MNIST has 1 channel\n",
    "image_size = 28  # 28x28 images\n",
    "model_MEMvae_1layers= MEMVAE( n_levels, num_slots_list, slot_dim_list,latent_dim,hidden_dim,image_channels,image_size).to(device)\n",
    "model_MEMvae_1layers.load_state_dict(state_dict_MEMvae)\n",
    "model_MEMvae_1layers.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b3c29a-9b83-40ba-a488-4dd2135e1979",
   "metadata": {},
   "outputs": [],
   "source": [
    "from VAE import VAE\n",
    "model_vae  = VAE(latent_dim=20,hidden_dim=128,image_channels=1,image_size=28).to(device)\n",
    "model_vae.load_state_dict(state_dict_vae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203c5cfd-f9a0-43fd-8f62-d0d74bd092f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_salt_and_pepper_noise(images, salt_prob=0.05, pepper_prob=0.05):\n",
    "    \"\"\"\n",
    "        Add salt-and-pepper noise to input images\n",
    "    \n",
    "    Args:\n",
    "        images (torch.Tensor): Input image tensor with shape [batch_size, channels, height, width]\n",
    "        salt_prob (float, optional): Probability of adding salt noise. Default: 0.05\n",
    "        pepper_prob (float, optional): Probability of adding pepper noise. Default: 0.05\n",
    "    \n",
    "    Returns:\n",
    "        torch.Tensor: Noisy image tensor with same shape as input\n",
    "    \"\"\"\n",
    " \n",
    "    if not torch.is_tensor(images):\n",
    "        raise TypeError(\"Input images should  be a tensor\")\n",
    "\n",
    "   \n",
    "    noise = torch.rand(images.shape[0], 1, images.shape[2], images.shape[3], device=images.device)\n",
    "\n",
    "    \n",
    "    salt_mask = (noise < salt_prob).float()  \n",
    "    images_with_salt = torch.where(salt_mask.expand_as(images) == 1, torch.ones_like(images), images)\n",
    "\n",
    "    pepper_mask = (noise > (1 - pepper_prob)).float() \n",
    "    images_with_salt_and_pepper = torch.where(pepper_mask.expand_as(images) == 1, torch.zeros_like(images_with_salt), images_with_salt)\n",
    "\n",
    "    return images_with_salt_and_pepper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c53d26-8718-4db0-bb57-f49be659c2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_gaussian_noise(images, mean=0.0, std=0.3):\n",
    "    \"\"\"\n",
    "    Add Gaussian noise to input images\n",
    "    Args:\n",
    "        images (torch.Tensor): Input image tensor with shape [batch_size, channels, height, width]\n",
    "        mean (float, optional): Mean of the Gaussian noise. Default: 0.0\n",
    "        std (float, optional): Standard deviation of the Gaussian noise. Default: 0.1\n",
    "    Returns:\n",
    "        torch.Tensor: Noisy image tensor with same shape as input\n",
    "    \"\"\"\n",
    "    if not torch.is_tensor(images):\n",
    "        raise TypeError(\"Input images should be a tensor\")\n",
    "    \n",
    "    noise = torch.randn_like(images) * std + mean\n",
    "    noisy_images = torch.clamp(images + noise, -1.0, 1.0)\n",
    "    \n",
    "    return noisy_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2f59ff-c992-44d7-8795-bbf116462331",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_dynamic_mask_noise(images, max_num_masks=5, max_mask_ratio=0.3):\n",
    "    \"\"\"\n",
    "    Add dynamic rectangle masking noise (automatically adapts to image dimensions)\n",
    "    \n",
    "    Args:\n",
    "        images (torch.Tensor): Input image tensor with shape [batch_size, channels, height, width]\n",
    "        max_num_masks (int, optional): Maximum number of masks per image. Default: 5\n",
    "        max_mask_ratio (float, optional): Maximum area ratio (0-1) for each mask relative to image size. Default: 0.3\n",
    "    \n",
    "    Returns:\n",
    "        torch.Tensor: Noisy image tensor with same shape as input\n",
    "    \"\"\"\n",
    "    if not torch.is_tensor(images):\n",
    "        raise TypeError(\"Input images should be a tensor\")\n",
    "    \n",
    "    device = images.device\n",
    "    noisy_images = images.clone()\n",
    "    b, c, h, w = images.shape\n",
    "    \n",
    "    for bidx in range(b):\n",
    "        num_masks = torch.randint(1, max_num_masks+1, (1,)).item()\n",
    "        \n",
    "        for _ in range(num_masks):\n",
    "            max_dim = int(min(h, w) * max_mask_ratio)\n",
    "            mask_h = torch.randint(1, max_dim+1, (1,), device=device)\n",
    "            mask_w = torch.randint(1, max_dim+1, (1,), device=device)\n",
    "            \n",
    "            x = torch.randint(0, w - mask_w + 1, (1,), device=device)\n",
    "            y = torch.randint(0, h - mask_h + 1, (1,), device=device)\n",
    "            \n",
    "            noise_value = torch.rand(1, device=device)\n",
    "            noisy_images[bidx, :, y:y+mask_h, x:x+mask_w] = noise_value\n",
    "    \n",
    "    return noisy_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5383942a-ed4e-4969-bb17-5bcc60b225c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_combined_comparison(samples_dict, save_dir=None, figsize=(24, 12)):\n",
    "    plt.figure(figsize=figsize)\n",
    "    num_models = len(samples_dict)\n",
    "    \n",
    "    NORM_MEAN = 0.1307\n",
    "    NORM_STD = 0.3081\n",
    "\n",
    "    def denormalize(tensor):\n",
    "        return torch.clamp(tensor * NORM_STD + NORM_MEAN, 0.0, 1.0)\n",
    "\n",
    "    if save_dir is not None:\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "        timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        save_path = os.path.join(save_dir, f\"denoising_comparison_{timestamp}.png\")\n",
    "    else:\n",
    "        save_path = None\n",
    "\n",
    "    ref_samples = next(iter(samples_dict.values()))[1]\n",
    "    original = ref_samples[0]  # [64, 1, 28, 28]\n",
    "    noisy = ref_samples[1]     \n",
    "\n",
    "    def prepare_grid(tensor, denorm=False):\n",
    "        if denorm:\n",
    "            tensor = denormalize(tensor)\n",
    "        grid = torchvision.utils.make_grid(tensor.cpu(), nrow=8, padding=2, normalize=False)\n",
    "        return grid.permute(1, 2, 0).numpy()  # CHW -> HWC\n",
    "\n",
    "   \n",
    "    plt.subplot(2, num_models+2, 1)\n",
    "    orig_grid = prepare_grid(original)\n",
    "    plt.imshow(orig_grid, cmap='gray')\n",
    "    plt.title(\"Original Images\")\n",
    "    plt.axis('off')\n",
    "\n",
    "    \n",
    "    plt.subplot(2, num_models+2, 2)\n",
    "    noisy_grid = prepare_grid(noisy, denorm=True)\n",
    "    plt.imshow(noisy_grid, cmap='gray')\n",
    "    plt.title(\"Noisy Inputs\")\n",
    "    plt.axis('off')\n",
    "\n",
    "   \n",
    "    for idx, (model_name, (mse, samples)) in enumerate(samples_dict.items()):\n",
    "        gen_images = samples[2]  \n",
    "        \n",
    "        plt.subplot(2, num_models+2, idx+3)\n",
    "        gen_grid = prepare_grid(gen_images)\n",
    "        plt.imshow(gen_grid, cmap='gray')\n",
    "        plt.title(f\"{model_name}\")\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, bbox_inches='tight', dpi=300)\n",
    "        print(f\"save：{save_path}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582ac7fa-9960-4b8e-b2cb-040533e87be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_generator_mse(model, test_loader, device, add_noise=True,\n",
    "                          mean=0.0, std=0.1, save_samples=False):\n",
    "    \"\"\"\n",
    "    Evaluate generative model and save sample comparisons\n",
    "    \n",
    "    Args:\n",
    "        save_samples (bool): Flag to enable saving comparison samples\n",
    "    \n",
    "    Returns:\n",
    "        float: Mean Squared Error (MSE) between generated and original images\n",
    "        tuple: When enabled, returns tuple containing:\n",
    "            - original_images (torch.Tensor): Ground truth images [batch_size, channels, height, width]\n",
    "            - noisy_inputs (torch.Tensor): Noisy input samples [batch_size, channels, height, width]\n",
    "            - generated_images (torch.Tensor): Model outputs [batch_size, channels, height, width]\n",
    "            Only returned if save_samples=True\n",
    "    \"\"\"\n",
    "    NORM_MEAN = 0.1307\n",
    "    NORM_STD = 0.3081\n",
    "    \n",
    "    def normalize(tensor):\n",
    "        return (tensor - NORM_MEAN) / NORM_STD\n",
    "    \n",
    "    def denormalize(tensor):\n",
    "        return torch.clamp(tensor * NORM_STD + NORM_MEAN, 0.0, 1.0)\n",
    "\n",
    "    model.eval()\n",
    "    mse_loss = nn.MSELoss()\n",
    "    mse_loss_none = nn.MSELoss(reduction='none')  \n",
    "    total_mse = 0.0\n",
    "    total_lpips = 0.0\n",
    "    total_ssim = 0.0  \n",
    "    total_samples = 0\n",
    "    total_psnr = 0.0\n",
    "    loss_fn = lpips.LPIPS(net='vgg').to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for idx, (images, _) in enumerate(test_loader):\n",
    "            \n",
    "            clean_images = denormalize(images.to(device))\n",
    "            \n",
    "          \n",
    "            if add_noise:\n",
    "                noisy_images =inputs = add_gaussian_noise(clean_images, mean, std)\n",
    "                inputs = normalize(noisy_images)  \n",
    "            else:\n",
    "                inputs = normalize(clean_images)  \n",
    "\n",
    "           \n",
    "            gen_data, _ = model(inputs)\n",
    "            gen_data = denormalize(gen_data)  \n",
    "            gen_data = gen_data.view(-1, 1, 28, 28)\n",
    "           \n",
    "            batch_mse = mse_loss(gen_data, clean_images)\n",
    "            batch_mse_per_sample = mse_loss_none(gen_data, clean_images)\n",
    "            batch_mse_per_sample = batch_mse_per_sample.view(batch_mse_per_sample.shape[0], -1).mean(dim=1)\n",
    "            batch_psnr = 10 * torch.log10(1.0 / (batch_mse_per_sample + 1e-10)).mean().item()\n",
    "            \n",
    "            clean_rgb = clean_images.repeat(1,3,1,1)  \n",
    "            gen_rgb = gen_data.repeat(1,3,1,1)\n",
    "            batch_lpips = loss_fn(clean_rgb, gen_rgb)\n",
    "             \n",
    "            batch_ssim = ssim(\n",
    "                gen_data, \n",
    "                clean_images,\n",
    "                data_range=1.0,  \n",
    "                size_average=True \n",
    "            )\n",
    "           \n",
    "            total_mse += batch_mse.item() * images.size(0)\n",
    "            total_lpips += batch_lpips.sum().item()\n",
    "            total_ssim += batch_ssim.item() * images.size(0)  \n",
    "            total_samples += images.size(0)\n",
    "            total_psnr += batch_psnr * images.size(0)\n",
    "            \n",
    "            if save_samples and idx == 0:\n",
    "                samples = (\n",
    "                    clean_images[:64].cpu(),\n",
    "                    inputs[:64].cpu(),\n",
    "                    gen_data[:64].cpu()\n",
    "                )\n",
    "    \n",
    "    avg_mse = total_mse / total_samples\n",
    "    avg_lpips = total_lpips / total_samples\n",
    "    avg_ssim = total_ssim / total_samples  \n",
    "    avg_psnr = total_psnr / total_samples\n",
    "    return avg_mse, avg_lpips,avg_ssim ,avg_psnr, samples\n",
    "models = {\n",
    "    \"VAE\": model_vae,\n",
    "    \"MEMVAE\": model_MEMvae_1layers,\n",
    "    \"HMVAE\": model_hmvae\n",
    "}\n",
    "samples_dict = {}\n",
    "for model_name, model in models.items():\n",
    "    mse,lpip,ssim_val, psnr_val,samples = evaluate_generator_mse(\n",
    "        model, test_loader, device, \n",
    "        add_noise=True, save_samples=True\n",
    "    )\n",
    "    print(f\"{model_name.ljust(15)} | MSE: {mse:.4f} | LPIPS: {lpip:.4f} | SSIM: {ssim_val:.4f} | PSNR: {psnr_val:.2f} dB\")\n",
    "    samples_dict[model_name] = (mse, samples)\n",
    "\n",
    "plot_combined_comparison(\n",
    "    samples_dict,\n",
    "    save_dir=\"./gaussian0.1_noise_results\",\n",
    "    figsize=(24, 12)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9531ed-815d-4cf7-b413-635087353adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_generator_mse(model, test_loader, device, add_noise=True,\n",
    "                          mean=0.0, std=0.2, save_samples=False):\n",
    "    \"\"\"\n",
    "    Evaluate generative model and save sample comparisons\n",
    "    \n",
    "    Args:\n",
    "        save_samples (bool): Flag to enable saving comparison samples\n",
    "    \n",
    "    Returns:\n",
    "        float: Mean Squared Error (MSE) between generated and original images\n",
    "        tuple: When enabled, returns tuple containing:\n",
    "            - original_images (torch.Tensor): Ground truth images [batch_size, channels, height, width]\n",
    "            - noisy_inputs (torch.Tensor): Noisy input samples [batch_size, channels, height, width]\n",
    "            - generated_images (torch.Tensor): Model outputs [batch_size, channels, height, width]\n",
    "            Only returned if save_samples=True\n",
    "    \"\"\"\n",
    "\n",
    "    NORM_MEAN = 0.1307\n",
    "    NORM_STD = 0.3081\n",
    "    \n",
    "    def normalize(tensor):\n",
    "        return (tensor - NORM_MEAN) / NORM_STD\n",
    "    \n",
    "    def denormalize(tensor):\n",
    "        return torch.clamp(tensor * NORM_STD + NORM_MEAN, 0.0, 1.0)\n",
    "\n",
    "    model.eval()\n",
    "    mse_loss = nn.MSELoss()\n",
    "    mse_loss_none = nn.MSELoss(reduction='none')  \n",
    "    total_mse = 0.0\n",
    "    total_lpips = 0.0\n",
    "    total_ssim = 0.0 \n",
    "    total_samples = 0\n",
    "    total_psnr = 0.0\n",
    "    loss_fn = lpips.LPIPS(net='vgg').to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for idx, (images, _) in enumerate(test_loader):\n",
    "           \n",
    "            clean_images = denormalize(images.to(device))\n",
    "            \n",
    "          \n",
    "            if add_noise:\n",
    "                noisy_images =inputs = add_gaussian_noise(clean_images, mean, std)\n",
    "                inputs = normalize(noisy_images) \n",
    "            else:\n",
    "                inputs = normalize(clean_images) \n",
    "\n",
    "           \n",
    "            gen_data, _ = model(inputs)\n",
    "            gen_data = denormalize(gen_data) \n",
    "            gen_data = gen_data.view(-1, 1, 28, 28)\n",
    "           \n",
    "            batch_mse = mse_loss(gen_data, clean_images)\n",
    "            batch_mse_per_sample = mse_loss_none(gen_data, clean_images)\n",
    "            batch_mse_per_sample = batch_mse_per_sample.view(batch_mse_per_sample.shape[0], -1).mean(dim=1)\n",
    "            batch_psnr = 10 * torch.log10(1.0 / (batch_mse_per_sample + 1e-10)).mean().item()\n",
    "            \n",
    "            clean_rgb = clean_images.repeat(1,3,1,1)  \n",
    "            gen_rgb = gen_data.repeat(1,3,1,1)\n",
    "            batch_lpips = loss_fn(clean_rgb, gen_rgb)\n",
    "            \n",
    "            batch_ssim = ssim(\n",
    "                gen_data, \n",
    "                clean_images,\n",
    "                data_range=1.0,  \n",
    "                size_average=True  \n",
    "            )\n",
    "            \n",
    "            total_mse += batch_mse.item() * images.size(0)\n",
    "            total_lpips += batch_lpips.sum().item()\n",
    "            total_ssim += batch_ssim.item() * images.size(0)  \n",
    "            total_samples += images.size(0)\n",
    "            total_psnr += batch_psnr * images.size(0)\n",
    "            \n",
    "            if save_samples and idx == 0:\n",
    "                samples = (\n",
    "                    clean_images[:64].cpu(),\n",
    "                    inputs[:64].cpu(),\n",
    "                    gen_data[:64].cpu()\n",
    "                )\n",
    "    \n",
    "    avg_mse = total_mse / total_samples\n",
    "    avg_lpips = total_lpips / total_samples\n",
    "    avg_ssim = total_ssim / total_samples  \n",
    "    avg_psnr = total_psnr / total_samples\n",
    "    return avg_mse, avg_lpips,avg_ssim ,avg_psnr, samples\n",
    "models = {\n",
    "    \"VAE\": model_vae,\n",
    "    \"MEMVAE\": model_MEMvae_1layers,\n",
    "    \"HMVAE\": model_hmvae\n",
    "}\n",
    "samples_dict = {}\n",
    "for model_name, model in models.items():\n",
    "    mse,lpip,ssim_val, psnr_val,samples = evaluate_generator_mse(\n",
    "        model, test_loader, device, \n",
    "        add_noise=True, save_samples=True\n",
    "    )\n",
    "    print(f\"{model_name.ljust(15)} | MSE: {mse:.4f} | LPIPS: {lpip:.4f} | SSIM: {ssim_val:.4f} | PSNR: {psnr_val:.2f} dB\")\n",
    "    samples_dict[model_name] = (mse, samples)\n",
    "\n",
    "plot_combined_comparison(\n",
    "    samples_dict,\n",
    "    save_dir=\"./gaussian0.2_noise_results\",\n",
    "    figsize=(24, 12)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a46234-35b0-4858-b679-3e8492a5068a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_generator_mse(model, test_loader, device, add_noise=True,\n",
    "                          mean=0.0, std=0.3, save_samples=False):\n",
    "    \"\"\"\n",
    "    Evaluate generative model and save sample comparisons\n",
    "    \n",
    "    Args:\n",
    "        save_samples (bool): Flag to enable saving comparison samples\n",
    "    \n",
    "    Returns:\n",
    "        float: Mean Squared Error (MSE) between generated and original images\n",
    "        tuple: When enabled, returns tuple containing:\n",
    "            - original_images (torch.Tensor): Ground truth images [batch_size, channels, height, width]\n",
    "            - noisy_inputs (torch.Tensor): Noisy input samples [batch_size, channels, height, width]\n",
    "            - generated_images (torch.Tensor): Model outputs [batch_size, channels, height, width]\n",
    "            Only returned if save_samples=True\n",
    "    \"\"\"\n",
    " \n",
    "    NORM_MEAN = 0.1307\n",
    "    NORM_STD = 0.3081\n",
    "    \n",
    "    def normalize(tensor):\n",
    "        return (tensor - NORM_MEAN) / NORM_STD\n",
    "    \n",
    "    def denormalize(tensor):\n",
    "        return torch.clamp(tensor * NORM_STD + NORM_MEAN, 0.0, 1.0)\n",
    "\n",
    "    model.eval()\n",
    "    mse_loss = nn.MSELoss()\n",
    "    mse_loss_none = nn.MSELoss(reduction='none') \n",
    "    total_mse = 0.0\n",
    "    total_lpips = 0.0\n",
    "    total_ssim = 0.0 \n",
    "    total_samples = 0\n",
    "    total_psnr = 0.0\n",
    "    loss_fn = lpips.LPIPS(net='vgg').to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for idx, (images, _) in enumerate(test_loader):\n",
    "            \n",
    "            clean_images = denormalize(images.to(device))\n",
    "            \n",
    "            \n",
    "            if add_noise:\n",
    "                noisy_images =inputs = add_gaussian_noise(clean_images, mean, std)\n",
    "                inputs = normalize(noisy_images)  \n",
    "            else:\n",
    "                inputs = normalize(clean_images) \n",
    "\n",
    "           \n",
    "            gen_data, _ = model(inputs)\n",
    "            gen_data = denormalize(gen_data) \n",
    "            gen_data = gen_data.view(-1, 1, 28, 28)\n",
    "           \n",
    "            batch_mse = mse_loss(gen_data, clean_images)\n",
    "            batch_mse_per_sample = mse_loss_none(gen_data, clean_images)\n",
    "            batch_mse_per_sample = batch_mse_per_sample.view(batch_mse_per_sample.shape[0], -1).mean(dim=1)\n",
    "            batch_psnr = 10 * torch.log10(1.0 / (batch_mse_per_sample + 1e-10)).mean().item()\n",
    "            \n",
    "            clean_rgb = clean_images.repeat(1,3,1,1)  \n",
    "            gen_rgb = gen_data.repeat(1,3,1,1)\n",
    "            batch_lpips = loss_fn(clean_rgb, gen_rgb)\n",
    "             \n",
    "            batch_ssim = ssim(\n",
    "                gen_data, \n",
    "                clean_images,\n",
    "                data_range=1.0,  \n",
    "                size_average=True  \n",
    "            )\n",
    "            total_mse += batch_mse.item() * images.size(0)\n",
    "            total_lpips += batch_lpips.sum().item()\n",
    "            total_ssim += batch_ssim.item() * images.size(0)  \n",
    "            total_samples += images.size(0)\n",
    "            total_psnr += batch_psnr * images.size(0)\n",
    "           \n",
    "            if save_samples and idx == 0:\n",
    "                samples = (\n",
    "                    clean_images[:64].cpu(),\n",
    "                    inputs[:64].cpu(),\n",
    "                    gen_data[:64].cpu()\n",
    "                )\n",
    "    \n",
    "    avg_mse = total_mse / total_samples\n",
    "    avg_lpips = total_lpips / total_samples\n",
    "    avg_ssim = total_ssim / total_samples  \n",
    "    avg_psnr = total_psnr / total_samples\n",
    "    return avg_mse, avg_lpips,avg_ssim ,avg_psnr, samples\n",
    "models = {\n",
    "    \"VAE\": model_vae,\n",
    "    \"MEMVAE\": model_MEMvae_1layers,\n",
    "    \"HMVAE\": model_hmvae\n",
    "}\n",
    "samples_dict = {}\n",
    "for model_name, model in models.items():\n",
    "    mse,lpip,ssim_val, psnr_val,samples = evaluate_generator_mse(\n",
    "        model, test_loader, device, \n",
    "        add_noise=True, save_samples=True\n",
    "    )\n",
    "    print(f\"{model_name.ljust(15)} | MSE: {mse:.4f} | LPIPS: {lpip:.4f} | SSIM: {ssim_val:.4f} | PSNR: {psnr_val:.2f} dB\")\n",
    "    samples_dict[model_name] = (mse, samples)\n",
    "\n",
    "plot_combined_comparison(\n",
    "    samples_dict,\n",
    "    save_dir=\"./gaussian0.3_noise_results\",\n",
    "    figsize=(24, 12)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3151cc6-9e16-462d-82d9-a90e5ebe9794",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_generator_mse(model, test_loader, device, add_noise=True,\n",
    "                          mean=0.0, std=0.4, save_samples=False):\n",
    "    \"\"\"\n",
    "    Evaluate generative model and save sample comparisons\n",
    "    \n",
    "    Args:\n",
    "        save_samples (bool): Flag to enable saving comparison samples\n",
    "    \n",
    "    Returns:\n",
    "        float: Mean Squared Error (MSE) between generated and original images\n",
    "        tuple: When enabled, returns tuple containing:\n",
    "            - original_images (torch.Tensor): Ground truth images [batch_size, channels, height, width]\n",
    "            - noisy_inputs (torch.Tensor): Noisy input samples [batch_size, channels, height, width]\n",
    "            - generated_images (torch.Tensor): Model outputs [batch_size, channels, height, width]\n",
    "            Only returned if save_samples=True\n",
    "    \"\"\"\n",
    "    \n",
    "    NORM_MEAN = 0.1307\n",
    "    NORM_STD = 0.3081\n",
    "    \n",
    "    def normalize(tensor):\n",
    "        return (tensor - NORM_MEAN) / NORM_STD\n",
    "    \n",
    "    def denormalize(tensor):\n",
    "        return torch.clamp(tensor * NORM_STD + NORM_MEAN, 0.0, 1.0)\n",
    "\n",
    "    model.eval()\n",
    "    mse_loss = nn.MSELoss()\n",
    "    mse_loss_none = nn.MSELoss(reduction='none') \n",
    "    total_mse = 0.0\n",
    "    total_lpips = 0.0\n",
    "    total_ssim = 0.0 \n",
    "    total_samples = 0\n",
    "    total_psnr = 0.0\n",
    "    loss_fn = lpips.LPIPS(net='vgg').to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for idx, (images, _) in enumerate(test_loader):\n",
    "           \n",
    "            clean_images = denormalize(images.to(device))\n",
    "            \n",
    "            \n",
    "            if add_noise:\n",
    "                noisy_images =inputs = add_gaussian_noise(clean_images, mean, std)\n",
    "                inputs = normalize(noisy_images)  \n",
    "            else:\n",
    "                inputs = normalize(clean_images)  \n",
    "\n",
    "            \n",
    "            gen_data, _ = model(inputs)\n",
    "            gen_data = denormalize(gen_data)  \n",
    "            gen_data = gen_data.view(-1, 1, 28, 28)\n",
    "           \n",
    "            batch_mse = mse_loss(gen_data, clean_images)\n",
    "            batch_mse_per_sample = mse_loss_none(gen_data, clean_images)\n",
    "            batch_mse_per_sample = batch_mse_per_sample.view(batch_mse_per_sample.shape[0], -1).mean(dim=1)\n",
    "            batch_psnr = 10 * torch.log10(1.0 / (batch_mse_per_sample + 1e-10)).mean().item()\n",
    "            \n",
    "            clean_rgb = clean_images.repeat(1,3,1,1) \n",
    "            gen_rgb = gen_data.repeat(1,3,1,1)\n",
    "            batch_lpips = loss_fn(clean_rgb, gen_rgb)\n",
    "            \n",
    "            batch_ssim = ssim(\n",
    "                gen_data, \n",
    "                clean_images,\n",
    "                data_range=1.0,  \n",
    "                size_average=True  \n",
    "            )\n",
    "           \n",
    "            total_mse += batch_mse.item() * images.size(0)\n",
    "            total_lpips += batch_lpips.sum().item()\n",
    "            total_ssim += batch_ssim.item() * images.size(0)  \n",
    "            total_samples += images.size(0)\n",
    "            total_psnr += batch_psnr * images.size(0)\n",
    "            \n",
    "            if save_samples and idx == 0:\n",
    "                samples = (\n",
    "                    clean_images[:64].cpu(),\n",
    "                    inputs[:64].cpu(),\n",
    "                    gen_data[:64].cpu()\n",
    "                )\n",
    "    \n",
    "    avg_mse = total_mse / total_samples\n",
    "    avg_lpips = total_lpips / total_samples\n",
    "    avg_ssim = total_ssim / total_samples  \n",
    "    avg_psnr = total_psnr / total_samples\n",
    "    return avg_mse, avg_lpips,avg_ssim ,avg_psnr, samples\n",
    "models = {\n",
    "    \"VAE\": model_vae,\n",
    "    \"MEMVAE\": model_MEMvae_1layers,\n",
    "    \"HMVAE\": model_hmvae\n",
    "}\n",
    "samples_dict = {}\n",
    "for model_name, model in models.items():\n",
    "    mse,lpip,ssim_val, psnr_val,samples = evaluate_generator_mse(\n",
    "        model, test_loader, device, \n",
    "        add_noise=True, save_samples=True\n",
    "    )\n",
    "    print(f\"{model_name.ljust(15)} | MSE: {mse:.4f} | LPIPS: {lpip:.4f} | SSIM: {ssim_val:.4f} | PSNR: {psnr_val:.2f} dB\")\n",
    "    samples_dict[model_name] = (mse, samples)\n",
    "\n",
    "plot_combined_comparison(\n",
    "    samples_dict,\n",
    "    save_dir=\"./gaussian0.4_noise_results\",\n",
    "    figsize=(24, 12)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b057b90-c5b6-4c0d-a878-95568b445861",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_generator_mse(model, test_loader, device, add_noise=True,\n",
    "                          mean=0.0, std=0.5, save_samples=False):\n",
    "    \"\"\"\n",
    "    Evaluate generative model and save sample comparisons\n",
    "    \n",
    "    Args:\n",
    "        save_samples (bool): Flag to enable saving comparison samples\n",
    "    \n",
    "    Returns:\n",
    "        float: Mean Squared Error (MSE) between generated and original images\n",
    "        tuple: When enabled, returns tuple containing:\n",
    "            - original_images (torch.Tensor): Ground truth images [batch_size, channels, height, width]\n",
    "            - noisy_inputs (torch.Tensor): Noisy input samples [batch_size, channels, height, width]\n",
    "            - generated_images (torch.Tensor): Model outputs [batch_size, channels, height, width]\n",
    "            Only returned if save_samples=True\n",
    "    \"\"\"\n",
    "   \n",
    "    NORM_MEAN = 0.1307\n",
    "    NORM_STD = 0.3081\n",
    "    \n",
    "    def normalize(tensor):\n",
    "        return (tensor - NORM_MEAN) / NORM_STD\n",
    "    \n",
    "    def denormalize(tensor):\n",
    "        return torch.clamp(tensor * NORM_STD + NORM_MEAN, 0.0, 1.0)\n",
    "\n",
    "    model.eval()\n",
    "    mse_loss = nn.MSELoss()\n",
    "    mse_loss_none = nn.MSELoss(reduction='none')  \n",
    "    total_mse = 0.0\n",
    "    total_lpips = 0.0\n",
    "    total_ssim = 0.0\n",
    "    total_samples = 0\n",
    "    total_psnr = 0.0\n",
    "    loss_fn = lpips.LPIPS(net='vgg').to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for idx, (images, _) in enumerate(test_loader):\n",
    "           \n",
    "            clean_images = denormalize(images.to(device))\n",
    "            \n",
    "            \n",
    "            if add_noise:\n",
    "                noisy_images =inputs = add_gaussian_noise(clean_images, mean, std)\n",
    "                inputs = normalize(noisy_images)  \n",
    "            else:\n",
    "                inputs = normalize(clean_images) \n",
    "\n",
    "           \n",
    "            gen_data, _ = model(inputs)\n",
    "            gen_data = denormalize(gen_data)  \n",
    "            gen_data = gen_data.view(-1, 1, 28, 28)\n",
    "           \n",
    "            batch_mse = mse_loss(gen_data, clean_images)\n",
    "            batch_mse_per_sample = mse_loss_none(gen_data, clean_images)\n",
    "            batch_mse_per_sample = batch_mse_per_sample.view(batch_mse_per_sample.shape[0], -1).mean(dim=1)\n",
    "            batch_psnr = 10 * torch.log10(1.0 / (batch_mse_per_sample + 1e-10)).mean().item()\n",
    "            \n",
    "            clean_rgb = clean_images.repeat(1,3,1,1) \n",
    "            gen_rgb = gen_data.repeat(1,3,1,1)\n",
    "            batch_lpips = loss_fn(clean_rgb, gen_rgb)\n",
    "             \n",
    "            batch_ssim = ssim(\n",
    "                gen_data, \n",
    "                clean_images,\n",
    "                data_range=1.0,  \n",
    "                size_average=True  \n",
    "            )\n",
    "            \n",
    "            total_mse += batch_mse.item() * images.size(0)\n",
    "            total_lpips += batch_lpips.sum().item()\n",
    "            total_ssim += batch_ssim.item() * images.size(0)  \n",
    "            total_samples += images.size(0)\n",
    "            total_psnr += batch_psnr * images.size(0)\n",
    "            \n",
    "            if save_samples and idx == 0:\n",
    "                samples = (\n",
    "                    clean_images[:64].cpu(),\n",
    "                    inputs[:64].cpu(),\n",
    "                    gen_data[:64].cpu()\n",
    "                )\n",
    "    \n",
    "    avg_mse = total_mse / total_samples\n",
    "    avg_lpips = total_lpips / total_samples\n",
    "    avg_ssim = total_ssim / total_samples  \n",
    "    avg_psnr = total_psnr / total_samples\n",
    "    return avg_mse, avg_lpips,avg_ssim ,avg_psnr, samples\n",
    "models = {\n",
    "    \"VAE\": model_vae,\n",
    "    \"MEMVAE\": model_MEMvae_1layers,\n",
    "    \"HMVAE\": model_hmvae\n",
    "}\n",
    "samples_dict = {}\n",
    "for model_name, model in models.items():\n",
    "    mse,lpip,ssim_val, psnr_val,samples = evaluate_generator_mse(\n",
    "        model, test_loader, device, \n",
    "        add_noise=True, save_samples=True\n",
    "    )\n",
    "    print(f\"{model_name.ljust(15)} | MSE: {mse:.4f} | LPIPS: {lpip:.4f} | SSIM: {ssim_val:.4f} | PSNR: {psnr_val:.2f} dB\")\n",
    "    samples_dict[model_name] = (mse, samples)\n",
    "\n",
    "plot_combined_comparison(\n",
    "    samples_dict,\n",
    "    save_dir=\"./gaussian0.5_noise_results\",\n",
    "    figsize=(24, 12)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7453e919-4477-49ff-be9b-f51db6c2e20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_generator_mse(model, test_loader, device, add_noise=True, salt_prob=0.05, pepper_prob=0.05,save_samples=False):\n",
    "    \"\"\"\n",
    "    Evaluate generator model's MSE with and without noisy inputs\n",
    "    \n",
    "    Args:\n",
    "        generator (nn.Module): Pre-trained generator model\n",
    "        test_loader (DataLoader): Test dataloader containing 10,000 images\n",
    "        device (str, optional): Computation device ('cuda'/'cpu'). Default: 'cuda'\n",
    "        add_noise (bool, optional): Flag to add salt-and-pepper noise. Default: False\n",
    "        salt_prob (float, optional): Probability of salt noise. Default: 0.05\n",
    "        pepper_prob (float, optional): Probability of pepper noise. Default: 0.05\n",
    "    \n",
    "    Returns:\n",
    "        float: Mean Squared Error (MSE) between generated outputs and original images\n",
    "    \"\"\"\n",
    "   \n",
    "    NORM_MEAN = 0.1307\n",
    "    NORM_STD = 0.3081\n",
    "    \n",
    "    def normalize(tensor):\n",
    "        return (tensor - NORM_MEAN) / NORM_STD\n",
    "    \n",
    "    def denormalize(tensor):\n",
    "        return torch.clamp(tensor * NORM_STD + NORM_MEAN, 0.0, 1.0)\n",
    "\n",
    "    model.eval()\n",
    "    mse_loss = nn.MSELoss()\n",
    "    mse_loss_none = nn.MSELoss(reduction='none')  \n",
    "    total_mse = 0.0\n",
    "    total_lpips = 0.0\n",
    "    total_ssim = 0.0  \n",
    "    total_samples = 0\n",
    "    total_psnr = 0.0\n",
    "    loss_fn = lpips.LPIPS(net='vgg').to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for idx, (images, _) in enumerate(test_loader):\n",
    "            \n",
    "            clean_images = denormalize(images.to(device))\n",
    "            \n",
    "           \n",
    "            if add_noise:\n",
    "                noisy_images =inputs = add_salt_and_pepper_noise(clean_images, salt_prob, pepper_prob)\n",
    "                inputs = normalize(noisy_images)  \n",
    "            else:\n",
    "                inputs = normalize(clean_images)  \n",
    "\n",
    "          \n",
    "            gen_data, _ = model(inputs)\n",
    "            gen_data = denormalize(gen_data)  \n",
    "            gen_data = gen_data.view(-1, 1, 28, 28)\n",
    "            \n",
    "            batch_mse = mse_loss(gen_data, clean_images)\n",
    "            batch_mse_per_sample = mse_loss_none(gen_data, clean_images)\n",
    "            batch_mse_per_sample = batch_mse_per_sample.view(batch_mse_per_sample.shape[0], -1).mean(dim=1)\n",
    "            batch_psnr = 10 * torch.log10(1.0 / (batch_mse_per_sample + 1e-10)).mean().item()\n",
    "            \n",
    "            clean_rgb = clean_images.repeat(1,3,1,1)  \n",
    "            gen_rgb = gen_data.repeat(1,3,1,1)\n",
    "            \n",
    "            batch_lpips = loss_fn(clean_rgb, gen_rgb)\n",
    "           \n",
    "            batch_ssim = ssim(\n",
    "                gen_data, \n",
    "                clean_images,\n",
    "                data_range=1.0,  \n",
    "                size_average=True  \n",
    "            )\n",
    "          \n",
    "            total_mse += batch_mse.item() * images.size(0)\n",
    "            total_lpips += batch_lpips.sum().item()\n",
    "            total_ssim += batch_ssim.item() * images.size(0)  \n",
    "            total_samples += images.size(0)\n",
    "            total_psnr += batch_psnr * images.size(0)\n",
    "           \n",
    "            if save_samples and idx == 0:\n",
    "                samples = (\n",
    "                    clean_images[:64].cpu(),\n",
    "                    inputs[:64].cpu(),\n",
    "                    gen_data[:64].cpu()\n",
    "                )\n",
    "    \n",
    "    avg_mse = total_mse / total_samples\n",
    "    avg_lpips = total_lpips / total_samples\n",
    "    avg_ssim = total_ssim / total_samples\n",
    "    avg_psnr = total_psnr / total_samples\n",
    "    return avg_mse, avg_lpips,avg_ssim,avg_psnr, samples\n",
    "models = {\n",
    "    \"VAE\": model_vae,\n",
    "    \"MEMVAE\": model_MEMvae_1layers,\n",
    "    \"HMVAE\": model_hmvae\n",
    "}\n",
    "samples_dict = {}\n",
    "for model_name, model in models.items():\n",
    "    mse,lpip,ssim_val, psnr_val,samples = evaluate_generator_mse(\n",
    "        model, test_loader, device, \n",
    "        add_noise=True, save_samples=True\n",
    "    )\n",
    "    print(f\"{model_name.ljust(15)} | MSE: {mse:.4f} | LPIPS: {lpip:.4f} | SSIM: {ssim_val:.4f} | PSNR: {psnr_val:.2f} dB\")\n",
    "    samples_dict[model_name] = (mse, samples)\n",
    "\n",
    "plot_combined_comparison(\n",
    "    samples_dict,\n",
    "    save_dir=\"./salt_and_pepper_noise_results\",\n",
    "    figsize=(24, 12)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ad6bfe-9d48-44e9-9806-64b319f9c146",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_generator_mse(model, test_loader, device, add_noise=True, \n",
    "                          max_num_masks=5, max_mask_ratio=0.2, save_samples=False):\n",
    "   \n",
    "   \n",
    "    NORM_MEAN = 0.1307\n",
    "    NORM_STD = 0.3081\n",
    "    \n",
    "    def normalize(tensor):\n",
    "        return (tensor - NORM_MEAN) / NORM_STD\n",
    "    \n",
    "    def denormalize(tensor):\n",
    "        return torch.clamp(tensor * NORM_STD + NORM_MEAN, 0.0, 1.0)\n",
    "\n",
    "    model.eval()\n",
    "    mse_loss = nn.MSELoss()\n",
    "    mse_loss_none = nn.MSELoss(reduction='none')  \n",
    "    total_psnr = 0.0\n",
    "    total_mse = 0.0\n",
    "    total_lpips = 0.0\n",
    "    total_ssim = 0.0  \n",
    "    total_samples = 0\n",
    "    loss_fn = lpips.LPIPS(net='vgg').to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for idx, (images, _) in enumerate(test_loader):\n",
    "           \n",
    "            clean_images = denormalize(images.to(device))\n",
    "            \n",
    "            \n",
    "            if add_noise:\n",
    "                noisy_images = add_dynamic_mask_noise(clean_images, max_num_masks, max_mask_ratio)\n",
    "                inputs = normalize(noisy_images)  \n",
    "            else:\n",
    "                inputs = normalize(clean_images)  \n",
    "\n",
    "           \n",
    "            gen_data, _ = model(inputs)\n",
    "            gen_data = denormalize(gen_data) \n",
    "            gen_data = gen_data.view(-1, 1, 28, 28)\n",
    "           \n",
    "           \n",
    "            batch_mse = mse_loss(gen_data, clean_images)\n",
    "            batch_mse_per_sample = mse_loss_none(gen_data, clean_images)\n",
    "            batch_mse_per_sample = batch_mse_per_sample.view(batch_mse_per_sample.shape[0], -1).mean(dim=1)\n",
    "            batch_psnr = 10 * torch.log10(1.0 / (batch_mse_per_sample + 1e-10)).mean().item()\n",
    "            \n",
    "            clean_rgb = clean_images.repeat(1,3,1,1)  \n",
    "            gen_rgb = gen_data.repeat(1,3,1,1)\n",
    "            batch_lpips = loss_fn(clean_rgb, gen_rgb)\n",
    "            \n",
    "            \n",
    "            batch_ssim = ssim(\n",
    "                gen_data, \n",
    "                clean_images,\n",
    "                data_range=1.0,  \n",
    "                size_average=True  \n",
    "            )\n",
    "            \n",
    "            total_psnr += batch_psnr * images.size(0)\n",
    "            total_mse += batch_mse.item() * images.size(0)\n",
    "            total_lpips += batch_lpips.sum().item()\n",
    "            total_ssim += batch_ssim.item() * images.size(0)  \n",
    "            total_samples += images.size(0)\n",
    "            \n",
    "            \n",
    "            if save_samples and idx == 0:\n",
    "                samples = (\n",
    "                    clean_images[:64].cpu(),\n",
    "                    inputs[:64].cpu(),\n",
    "                    gen_data[:64].cpu()\n",
    "                )\n",
    "    \n",
    "    avg_mse = total_mse / total_samples\n",
    "    avg_lpips = total_lpips / total_samples\n",
    "    avg_ssim = total_ssim / total_samples \n",
    "    avg_psnr = total_psnr / total_samples\n",
    "    return avg_mse, avg_lpips, avg_ssim ,avg_psnr,samples\n",
    "models = {\n",
    "    \"VAE\": model_vae,\n",
    "    \"MEMVAE\": model_MEMvae_1layers,\n",
    "    \"HMVAE\": model_hmvae\n",
    "}\n",
    "samples_dict = {}\n",
    "for model_name, model in models.items():\n",
    "    mse,lpip,ssim_val, psnr_val,samples = evaluate_generator_mse(\n",
    "        model, test_loader, device, \n",
    "        add_noise=True, save_samples=True\n",
    "    )\n",
    "    print(f\"{model_name.ljust(15)} | MSE: {mse:.4f} | LPIPS: {lpip:.4f} | SSIM: {ssim_val:.4f} | PSNR: {psnr_val:.2f} dB\")\n",
    "    samples_dict[model_name] = (mse, samples)\n",
    "\n",
    "plot_combined_comparison(\n",
    "    samples_dict,\n",
    "    save_dir=\"./dynamic_mask_noise_results\",\n",
    "    figsize=(24, 12)\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
