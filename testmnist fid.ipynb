{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2da17bec-1b2e-45a4-a019-00dfdd043a1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-29 14:40:04.756013\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.utils import save_image\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import save_image\n",
    "import torchvision.utils as vutils\n",
    "import os\n",
    "import glob\n",
    "import datetime\n",
    "import time\n",
    "start_time = datetime.datetime.now()\n",
    "print(start_time)\n",
    "\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0e56a47-4161-49b9-98be-6650c200df74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:3\")\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5552c4ed-c757-45eb-b67c-fc9b15a78b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# state_dict\n",
    "model_path_hmvae = './saved_models_hmvae_mnist/model_epoch_496_loss_21.7908.pt'\n",
    "state_dict = torch.load(model_path_hmvae, map_location=device)\n",
    "model_path_MEMvae = './saved_models_MEMvae_mnist/model_epoch_498_loss_22.3760.pt'\n",
    "state_dict_MEMvae = torch.load(model_path_MEMvae, map_location=device)\n",
    "model_path_vae = './saved_models_vae_mnist/model_epoch_492_loss_23.7127.pt'\n",
    "state_dict_vae = torch.load(model_path_vae, map_location=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6b8bc8-e6c9-42b7-93e2-48c1aa3aa7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "\n",
    "mnist_test = MNIST(root=\"./mnistdata\", train=False, download=True)\n",
    "real_images_dir = \"./mnist_real_images\"\n",
    "os.makedirs(real_images_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "for i, (img_pil, label) in enumerate(mnist_test):\n",
    "    img_pil.save(os.path.join(real_images_dir, f\"image_{i:04d}.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1ab315-76bf-4a11-98be-46a6b760febf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HMVAE(\n",
       "  (encoder): Encoder(\n",
       "    (linears): Sequential(\n",
       "      (0): Linear(in_features=784, out_features=256, bias=True)\n",
       "      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "      (3): Linear(in_features=256, out_features=128, bias=True)\n",
       "      (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU()\n",
       "    )\n",
       "    (latent): Linear(in_features=128, out_features=20, bias=True)\n",
       "    (get_mu): Sequential(\n",
       "      (0): Linear(in_features=256, out_features=128, bias=True)\n",
       "      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "      (3): Linear(in_features=128, out_features=20, bias=True)\n",
       "    )\n",
       "    (get_logvar): Sequential(\n",
       "      (0): Linear(in_features=256, out_features=128, bias=True)\n",
       "      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "      (3): Linear(in_features=128, out_features=20, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (memorylayer1): BrainInspiredMemoryLayer(\n",
       "      (region_projectors): ModuleList(\n",
       "        (0): ModuleList(\n",
       "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (1): Linear(in_features=128, out_features=64, bias=True)\n",
       "          (2): Linear(in_features=256, out_features=64, bias=True)\n",
       "        )\n",
       "        (1): ModuleList(\n",
       "          (0): Linear(in_features=32, out_features=64, bias=True)\n",
       "          (1): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (2): Linear(in_features=128, out_features=64, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (region_projections): ModuleList(\n",
       "        (0): ModuleList(\n",
       "          (0): Linear(in_features=128, out_features=64, bias=True)\n",
       "          (1): Linear(in_features=64, out_features=128, bias=True)\n",
       "          (2): Linear(in_features=128, out_features=256, bias=True)\n",
       "        )\n",
       "        (1): ModuleList(\n",
       "          (0): Linear(in_features=128, out_features=32, bias=True)\n",
       "          (1): Linear(in_features=32, out_features=64, bias=True)\n",
       "          (2): Linear(in_features=64, out_features=128, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (reverse_projectors): ModuleList(\n",
       "        (0): ModuleList(\n",
       "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (1): Linear(in_features=64, out_features=128, bias=True)\n",
       "          (2): Linear(in_features=64, out_features=256, bias=True)\n",
       "        )\n",
       "        (1): ModuleList(\n",
       "          (0): Linear(in_features=64, out_features=32, bias=True)\n",
       "          (1): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (2): Linear(in_features=64, out_features=128, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (region_memories): ModuleList(\n",
       "        (0): ModuleList(\n",
       "          (0): RegionMemoryLevel(\n",
       "            (res_mlp): Sequential(\n",
       "              (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "              (1): Sigmoid()\n",
       "              (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "            )\n",
       "          )\n",
       "          (1): RegionMemoryLevel(\n",
       "            (res_mlp): Sequential(\n",
       "              (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (1): Sigmoid()\n",
       "              (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "            )\n",
       "          )\n",
       "          (2): RegionMemoryLevel(\n",
       "            (res_mlp): Sequential(\n",
       "              (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (1): Sigmoid()\n",
       "              (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): ModuleList(\n",
       "          (0): RegionMemoryLevel(\n",
       "            (res_mlp): Sequential(\n",
       "              (0): Linear(in_features=32, out_features=32, bias=True)\n",
       "              (1): Sigmoid()\n",
       "              (2): Linear(in_features=32, out_features=32, bias=True)\n",
       "            )\n",
       "          )\n",
       "          (1): RegionMemoryLevel(\n",
       "            (res_mlp): Sequential(\n",
       "              (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "              (1): Sigmoid()\n",
       "              (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "            )\n",
       "          )\n",
       "          (2): RegionMemoryLevel(\n",
       "            (res_mlp): Sequential(\n",
       "              (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (1): Sigmoid()\n",
       "              (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (cross_region_attn): ModuleList(\n",
       "        (0-2): 3 x Linear(in_features=64, out_features=2, bias=True)\n",
       "      )\n",
       "      (output_fusion): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (act): Sigmoid()\n",
       "      (final_proj): ModuleList(\n",
       "        (0): Linear(in_features=256, out_features=64, bias=True)\n",
       "        (1): Linear(in_features=128, out_features=64, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (memorylayer2): BrainInspiredMemoryLayer(\n",
       "      (region_projectors): ModuleList(\n",
       "        (0): ModuleList(\n",
       "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (1): Linear(in_features=128, out_features=64, bias=True)\n",
       "          (2): Linear(in_features=256, out_features=64, bias=True)\n",
       "        )\n",
       "        (1): ModuleList(\n",
       "          (0): Linear(in_features=32, out_features=64, bias=True)\n",
       "          (1): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (2): Linear(in_features=128, out_features=64, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (region_projections): ModuleList(\n",
       "        (0): ModuleList(\n",
       "          (0): Linear(in_features=256, out_features=64, bias=True)\n",
       "          (1): Linear(in_features=64, out_features=128, bias=True)\n",
       "          (2): Linear(in_features=128, out_features=256, bias=True)\n",
       "        )\n",
       "        (1): ModuleList(\n",
       "          (0): Linear(in_features=256, out_features=32, bias=True)\n",
       "          (1): Linear(in_features=32, out_features=64, bias=True)\n",
       "          (2): Linear(in_features=64, out_features=128, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (reverse_projectors): ModuleList(\n",
       "        (0): ModuleList(\n",
       "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (1): Linear(in_features=64, out_features=128, bias=True)\n",
       "          (2): Linear(in_features=64, out_features=256, bias=True)\n",
       "        )\n",
       "        (1): ModuleList(\n",
       "          (0): Linear(in_features=64, out_features=32, bias=True)\n",
       "          (1): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (2): Linear(in_features=64, out_features=128, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (region_memories): ModuleList(\n",
       "        (0): ModuleList(\n",
       "          (0): RegionMemoryLevel(\n",
       "            (res_mlp): Sequential(\n",
       "              (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "              (1): Sigmoid()\n",
       "              (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "            )\n",
       "          )\n",
       "          (1): RegionMemoryLevel(\n",
       "            (res_mlp): Sequential(\n",
       "              (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (1): Sigmoid()\n",
       "              (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "            )\n",
       "          )\n",
       "          (2): RegionMemoryLevel(\n",
       "            (res_mlp): Sequential(\n",
       "              (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (1): Sigmoid()\n",
       "              (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): ModuleList(\n",
       "          (0): RegionMemoryLevel(\n",
       "            (res_mlp): Sequential(\n",
       "              (0): Linear(in_features=32, out_features=32, bias=True)\n",
       "              (1): Sigmoid()\n",
       "              (2): Linear(in_features=32, out_features=32, bias=True)\n",
       "            )\n",
       "          )\n",
       "          (1): RegionMemoryLevel(\n",
       "            (res_mlp): Sequential(\n",
       "              (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "              (1): Sigmoid()\n",
       "              (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "            )\n",
       "          )\n",
       "          (2): RegionMemoryLevel(\n",
       "            (res_mlp): Sequential(\n",
       "              (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (1): Sigmoid()\n",
       "              (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (cross_region_attn): ModuleList(\n",
       "        (0-2): 3 x Linear(in_features=64, out_features=2, bias=True)\n",
       "      )\n",
       "      (output_fusion): Linear(in_features=128, out_features=256, bias=True)\n",
       "      (act): Sigmoid()\n",
       "      (final_proj): ModuleList(\n",
       "        (0): Linear(in_features=256, out_features=64, bias=True)\n",
       "        (1): Linear(in_features=128, out_features=64, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (linear1): Sequential(\n",
       "      (0): Linear(in_features=20, out_features=128, bias=True)\n",
       "      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "    (linear2): Sequential(\n",
       "      (0): Linear(in_features=128, out_features=256, bias=True)\n",
       "      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "    (ladder1): LadderCompositionLayer(\n",
       "      (nonlinearity): Sigmoid()\n",
       "      (nonlinearity_final): ReLU()\n",
       "    )\n",
       "    (ladder2): LadderCompositionLayer(\n",
       "      (nonlinearity): Sigmoid()\n",
       "      (nonlinearity_final): ReLU()\n",
       "    )\n",
       "    (final_linear): Linear(in_features=256, out_features=784, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from HMVAE import HMVAE\n",
    "n_levels = 3\n",
    "n_regions=2\n",
    "region_slot_config= [\n",
    "    ( [50, 50, 50], [64, 128, 256] ),  \n",
    "    ( [64, 64,64],   [32,64, 128] )       \n",
    "]\n",
    "latent_dim = 20\n",
    "hidden_dim =128\n",
    "image_channels = 1  # MNIST has 1 channel\n",
    "image_size = 28  # 28x28 images\n",
    "model_hmvae = HMVAE( n_levels, n_regions, region_slot_config,latent_dim,hidden_dim,image_channels,image_size).to(device)\n",
    "model_hmvae.load_state_dict(state_dict)\n",
    "model_hmvae.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fabedfc4-9ad5-42a6-8d70-f25a8db501ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MEMVAE(\n",
       "  (encoder): Encoder(\n",
       "    (linears): Sequential(\n",
       "      (0): Linear(in_features=784, out_features=256, bias=True)\n",
       "      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "      (3): Linear(in_features=256, out_features=128, bias=True)\n",
       "      (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU()\n",
       "    )\n",
       "    (latent): Linear(in_features=128, out_features=20, bias=True)\n",
       "    (get_mu): Sequential(\n",
       "      (0): Linear(in_features=256, out_features=128, bias=True)\n",
       "      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "      (3): Linear(in_features=128, out_features=20, bias=True)\n",
       "    )\n",
       "    (get_logvar): Sequential(\n",
       "      (0): Linear(in_features=256, out_features=128, bias=True)\n",
       "      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "      (3): Linear(in_features=128, out_features=20, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (memorylayer1): HierarchicalMemoryLayer(\n",
       "      (memory_banks): ParameterList(  (0): Parameter containing: [torch.float32 of size 50x64 (cuda:3)])\n",
       "      (controllers): ParameterList(  (0): Parameter containing: [torch.float32 of size 64x50 (cuda:3)])\n",
       "      (res_mlps): ModuleList(\n",
       "        (0): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (1): Sigmoid()\n",
       "          (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (projections): ModuleList(\n",
       "        (0): Identity()\n",
       "      )\n",
       "      (input_proj): Linear(in_features=128, out_features=64, bias=True)\n",
       "      (output_proj): Linear(in_features=64, out_features=128, bias=True)\n",
       "      (biases): ParameterList(  (0): Parameter containing: [torch.float32 of size 50 (cuda:3)])\n",
       "      (act): Sigmoid()\n",
       "    )\n",
       "    (memorylayer2): HierarchicalMemoryLayer(\n",
       "      (memory_banks): ParameterList(  (0): Parameter containing: [torch.float32 of size 50x64 (cuda:3)])\n",
       "      (controllers): ParameterList(  (0): Parameter containing: [torch.float32 of size 64x50 (cuda:3)])\n",
       "      (res_mlps): ModuleList(\n",
       "        (0): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (1): Sigmoid()\n",
       "          (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (projections): ModuleList(\n",
       "        (0): Identity()\n",
       "      )\n",
       "      (input_proj): Linear(in_features=256, out_features=64, bias=True)\n",
       "      (output_proj): Linear(in_features=64, out_features=256, bias=True)\n",
       "      (biases): ParameterList(  (0): Parameter containing: [torch.float32 of size 50 (cuda:3)])\n",
       "      (act): Sigmoid()\n",
       "    )\n",
       "    (linear1): Sequential(\n",
       "      (0): Linear(in_features=20, out_features=128, bias=True)\n",
       "      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "    (linear2): Sequential(\n",
       "      (0): Linear(in_features=128, out_features=256, bias=True)\n",
       "      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "    (ladder1): LadderCompositionLayer(\n",
       "      (nonlinearity): Sigmoid()\n",
       "      (nonlinearity_final): ReLU()\n",
       "    )\n",
       "    (ladder2): LadderCompositionLayer(\n",
       "      (nonlinearity): Sigmoid()\n",
       "      (nonlinearity_final): ReLU()\n",
       "    )\n",
       "    (final_linear): Linear(in_features=256, out_features=784, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Loading 1-layers\n",
    "from MEMVAE import MEMVAE\n",
    "n_levels = 1\n",
    "num_slots_list = [50]  # Just example sizes\n",
    "slot_dim_list = [64]  # Example embedding sizes\n",
    "latent_dim = 20\n",
    "hidden_dim =128\n",
    "image_channels = 1  # MNIST has 1 channel\n",
    "image_size = 28  # 28x28 images\n",
    "model_MEMvae= MEMVAE( n_levels, num_slots_list, slot_dim_list,latent_dim,hidden_dim,image_channels,image_size).to(device)\n",
    "model_MEMvae.load_state_dict(state_dict_MEMvae)\n",
    "model_MEMvae.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2b3c29a-9b83-40ba-a488-4dd2135e1979",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from VAE import VAE\n",
    "model_vae  = VAE(latent_dim=20,hidden_dim=128,image_channels=1,image_size=28).to(device)\n",
    "model_vae.load_state_dict(state_dict_vae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd701696-8fb9-4054-ad09-8482561b6921",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_from_latent(model, num_samples, save_dir, latent_dim=20):\n",
    "    model.eval()\n",
    "    \n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    with torch.no_grad():\n",
    "      \n",
    "        z = torch.randn(num_samples, latent_dim).to(device)\n",
    "        \n",
    "        if model == model_vae:\n",
    "            gen_data = model.decoder(z)  \n",
    "        else:\n",
    "            gen_data, _ = model.decoder(z)  \n",
    "            \n",
    "        gen_data = gen_data.view(-1, 1, 28, 28)\n",
    "        \n",
    "       \n",
    "        for i in range(num_samples):\n",
    "            img_path = os.path.join(save_dir, f'image_{i:04d}.png')  \n",
    "            vutils.save_image(gen_data[i], img_path, normalize=False)  \n",
    "\n",
    "\n",
    "generate_from_latent(model_vae, num_samples=10000, save_dir='./generated_images_vae')\n",
    "generate_from_latent(model_hmvae, num_samples=10000, save_dir='./generated_images_hmvae')\n",
    "generate_from_latent(model_MEMvae, num_samples=10000, save_dir='./generated_images_MEMVAE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480f3e02-60f8-477a-a8b9-c4a9ec39eeed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vae 的8x8网格图已保存到：./generated_grids\\vae_grid_8x8.png\n",
      "hmvae 的8x8网格图已保存到：./generated_grids\\hmvae_grid_8x8.png\n",
      "MEMVAE 的8x8网格图已保存到：./generated_grids\\MEMVAE_grid_8x8.png\n"
     ]
    }
   ],
   "source": [
    "import random \n",
    "from torchvision.utils import make_grid, save_image\n",
    "models = [\"vae\", \"hmvae\", \"MEMVAE\"]\n",
    "\n",
    "\n",
    "output_dir = \"./generated_grids\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "for model in models:\n",
    "    input_folder = f\"./generated_images_{model}\"\n",
    "    \n",
    "    \n",
    "    if not os.path.exists(input_folder):\n",
    "        print(f\"警告：{input_folder} 不存在，跳过\")\n",
    "        continue\n",
    "    \n",
    "    \n",
    "    all_images = glob.glob(os.path.join(input_folder, \"*.png\"))  \n",
    "    if len(all_images) < 64:\n",
    "        print(f\"警告：{input_folder} 中图像不足64张（实际有{len(all_images)}张），跳过\")\n",
    "        continue\n",
    "    \n",
    "   \n",
    "    image_paths = random.sample(all_images, 64)  \n",
    "    \n",
    "  \n",
    "    tensor_list = []\n",
    "    transform = transforms.ToTensor()\n",
    "    for img_path in image_paths:\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        tensor = transform(img).unsqueeze(0)  \n",
    "        tensor_list.append(tensor)\n",
    "    \n",
    "   \n",
    "    batch = torch.cat(tensor_list, dim=0)\n",
    "    grid = make_grid(batch, nrow=8, padding=2, normalize=True)\n",
    "    \n",
    "    \n",
    "    output_path = os.path.join(output_dir, f\"{model}_grid_8x8.png\")\n",
    "    save_image(grid, output_path)\n",
    "    print(f\"{model} 的8x8网格图已保存到：{output_path}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517439d9-d919-4c62-bab0-53b30355365c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "def convert_grayscale_to_rgb(image_path):\n",
    "    img = Image.open(image_path).convert(\"L\")  \n",
    "    img_rgb = np.stack([np.array(img)] * 3, axis=-1)  \n",
    "    Image.fromarray(img_rgb).save(image_path)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0bcfc4-117c-4b0a-b823-2e426e5c6706",
   "metadata": {},
   "outputs": [],
   "source": [
    "for img_path in glob.glob(\"./generated_images_vae/*.png\"):\n",
    "    convert_grayscale_to_rgb(img_path)\n",
    "for img_path in glob.glob(\"./generated_images_hmvae/*.png\"):\n",
    "    convert_grayscale_to_rgb(img_path)\n",
    "for img_path in glob.glob(\"./generated_images_MEMVAE/*.png\"):\n",
    "    convert_grayscale_to_rgb(img_path)\n",
    "\n",
    "for img_path in glob.glob(\"./mnist_real_images/*.png\"):\n",
    "    convert_grayscale_to_rgb(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7ca2377d-e1dd-4959-89f0-3e62d00f484e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID for vae: FID:  44.57462378884898\n",
      "\n",
      "FID for hmvae: FID:  27.84932459097979\n",
      "\n",
      "FID for MEMVAE: FID:  32.1096883541494\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "models = [\n",
    "    \"vae\", \n",
    "    \"hmvae\", \n",
    "    \"MEMVAE\"\n",
    "]\n",
    "for model in models:\n",
    "    gen_dir = f\"./generated_images_{model}\"\n",
    "    cmd = f\"python -m pytorch_fid  {gen_dir} ./mnist_real_images\"\n",
    "    result = subprocess.run(cmd, shell=True, capture_output=True, text=True)\n",
    "    print(f\"FID for {model}: {result.stdout}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae428d91-c054-44ca-b3f7-7195ae3da9c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ebdc314-7c39-47ea-9b40-c290e9d61e22",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
